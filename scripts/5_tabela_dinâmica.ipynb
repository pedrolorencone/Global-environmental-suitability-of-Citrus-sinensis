{
 "cells": [
  {
   "cell_type": "raw",
   "id": "44886d93",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6606ed3a",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def montar_resumo_xlsx(caminho_arquivo: Path):\n",
    "    # Lê todas as abas do arquivo\n",
    "    sheets = pd.read_excel(caminho_arquivo, sheet_name=None, engine=\"openpyxl\")\n",
    "\n",
    "    # Junta apenas as abas que têm as colunas necessárias (exceto 'resumo')\n",
    "    frames = []\n",
    "    for nome_aba, df in sheets.items():\n",
    "        if str(nome_aba).strip().lower() == \"resumo\":\n",
    "            continue\n",
    "        if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "            continue\n",
    "\n",
    "        # normaliza nomes de colunas\n",
    "        df = df.rename(columns=lambda c: str(c).strip())\n",
    "        colunas_ok = {\"name\", \"gridcode\", \"area_km2\"}.issubset(df.columns)\n",
    "\n",
    "        if colunas_ok:\n",
    "            df = df.copy()\n",
    "            # tipos numéricos\n",
    "            df[\"gridcode\"] = pd.to_numeric(df[\"gridcode\"], errors=\"coerce\")\n",
    "            df[\"area_km2\"] = pd.to_numeric(df[\"area_km2\"], errors=\"coerce\")\n",
    "            df = df.dropna(subset=[\"name\", \"gridcode\", \"area_km2\"])\n",
    "            frames.append(df[[\"name\", \"gridcode\", \"area_km2\"]])\n",
    "\n",
    "    if not frames:\n",
    "        print(f\"⚠️  {caminho_arquivo.name}: nenhuma aba com as colunas exigidas (name, gridcode, area_km2).\")\n",
    "        return\n",
    "\n",
    "    dados = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Tabela dinâmica\n",
    "    tabela = pd.pivot_table(\n",
    "        dados,\n",
    "        index=\"name\",\n",
    "        columns=\"gridcode\",\n",
    "        values=\"area_km2\",\n",
    "        aggfunc=\"sum\",\n",
    "        fill_value=0,\n",
    "        margins=True,\n",
    "        margins_name=\"TOTAL\"\n",
    "    )\n",
    "\n",
    "    # Ordena colunas por gridcode (TOTAL por último)\n",
    "    cols = [c for c in tabela.columns if c != \"TOTAL\"]\n",
    "    try:\n",
    "        cols_ordenadas = sorted(cols)  # se forem números, ordena numericamente\n",
    "    except Exception:\n",
    "        # fallback para string\n",
    "        cols_ordenadas = sorted(map(str, cols))\n",
    "        tabela.columns = [str(c) for c in tabela.columns]\n",
    "    if \"TOTAL\" in tabela.columns:\n",
    "        cols_ordenadas += [\"TOTAL\"]\n",
    "    tabela = tabela[cols_ordenadas]\n",
    "\n",
    "    # Salva na aba 'resumo' (substitui se já existir)\n",
    "    try:\n",
    "        with pd.ExcelWriter(\n",
    "            caminho_arquivo,\n",
    "            engine=\"openpyxl\",\n",
    "            mode=\"a\",\n",
    "            if_sheet_exists=\"replace\"\n",
    "        ) as writer:\n",
    "            tabela.to_excel(writer, sheet_name=\"resumo\")\n",
    "        print(f\"✅  {caminho_arquivo.name}: aba 'resumo' criada/atualizada.\")\n",
    "    except PermissionError:\n",
    "        print(f\"❌  {caminho_arquivo.name}: arquivo está aberto. Feche no Excel e tente de novo.\")\n",
    "\n",
    "def processar_pasta(pasta: str):\n",
    "    pasta = Path(pasta)\n",
    "    assert pasta.is_dir(), f\"Pasta não encontrada: {pasta}\"\n",
    "\n",
    "    arquivos = list(pasta.glob(\"*.xlsx\"))\n",
    "    if not arquivos:\n",
    "        print(\"Nenhum .xlsx encontrado na pasta.\")\n",
    "        return\n",
    "\n",
    "    for arq in arquivos:\n",
    "        try:\n",
    "            montar_resumo_xlsx(arq)\n",
    "        except Exception as e:\n",
    "            print(f\"❌  Erro em {arq.name}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # === EDITE AQUI O CAMINHO DA PASTA ===\n",
    "    processar_pasta(r\"D:\\ARTIGOS\\2025\\LARANJA_MAX\\04_SAIDA_MAXENT\\processamento\\7_excel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6602c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  2021_2040_ssp126.xlsx: 15/15 países, 59 linhas salvas em '2021_2040_ssp126.xlsx'.\n",
      "✅  2021_2040_ssp245.xlsx: 15/15 países, 15 linhas salvas em '2021_2040_ssp245.xlsx'.\n",
      "✅  2021_2040_ssp370.xlsx: 15/15 países, 15 linhas salvas em '2021_2040_ssp370.xlsx'.\n",
      "✅  2021_2040_ssp585.xlsx: 15/15 países, 15 linhas salvas em '2021_2040_ssp585.xlsx'.\n",
      "✅  2041_2060_ssp126.xlsx: 15/15 países, 15 linhas salvas em '2041_2060_ssp126.xlsx'.\n",
      "✅  2041_2060_ssp245.xlsx: 15/15 países, 15 linhas salvas em '2041_2060_ssp245.xlsx'.\n",
      "✅  2041_2060_ssp370.xlsx: 15/15 países, 15 linhas salvas em '2041_2060_ssp370.xlsx'.\n",
      "✅  2041_2060_ssp585.xlsx: 15/15 países, 15 linhas salvas em '2041_2060_ssp585.xlsx'.\n",
      "✅  2061_2080_ssp126.xlsx: 15/15 países, 15 linhas salvas em '2061_2080_ssp126.xlsx'.\n",
      "✅  2061_2080_ssp245.xlsx: 15/15 países, 15 linhas salvas em '2061_2080_ssp245.xlsx'.\n",
      "✅  2061_2080_ssp370.xlsx: 15/15 países, 15 linhas salvas em '2061_2080_ssp370.xlsx'.\n",
      "✅  2061_2080_ssp585.xlsx: 15/15 países, 15 linhas salvas em '2061_2080_ssp585.xlsx'.\n",
      "✅  2081_2100_ssp126.xlsx: 15/15 países, 15 linhas salvas em '2081_2100_ssp126.xlsx'.\n",
      "✅  2081_2100_ssp245.xlsx: 15/15 países, 15 linhas salvas em '2081_2100_ssp245.xlsx'.\n",
      "✅  2081_2100_ssp370.xlsx: 15/15 países, 15 linhas salvas em '2081_2100_ssp370.xlsx'.\n",
      "✅  2081_2100_ssp585.xlsx: 15/15 países, 15 linhas salvas em '2081_2100_ssp585.xlsx'.\n",
      "✅  actual.xlsx: 15/15 países, 15 linhas salvas em 'actual.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIG ===\n",
    "INPUT  = Path(r\"D:\\ARTIGOS\\2025\\LARANJA_MAX\\04_SAIDA_MAXENT\\processamento\\7_excel\")\n",
    "OUTPUT = Path(r\"D:\\ARTIGOS\\2025\\LARANJA_MAX\\07_POS_ANALISE\\15_PAISES\")\n",
    "SHEET_NAME = \"resumo\"\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PAISES_ORDEM = [\n",
    "    \"Brazil\",\"China\",\"India\",\"Mexico\",\"Spain\",\"Egypt\",\"United States\",\n",
    "    \"Indonesia\",\"Iran\",\"South Africa\",\"Pakistan\",\"Italy\",\"Algeria\",\n",
    "    \"Morocco\",\"Vietnam\"\n",
    "]\n",
    "\n",
    "# mapeia variações comuns -> nome canônico\n",
    "ALIASES = {\n",
    "    # EUA\n",
    "    \"United States of America\": \"United States\",\n",
    "    \"U.S.\": \"United States\",\n",
    "    \"USA\": \"United States\",\n",
    "    \"United States\": \"United States\",\n",
    "    # Irã\n",
    "    \"Iran (Islamic Republic of)\": \"Iran\",\n",
    "    \"IR Iran\": \"Iran\",\n",
    "    \"Iran\": \"Iran\",\n",
    "    # Vietnã (caso apareça como duas palavras)\n",
    "    \"Viet Nam\": \"Vietnam\",\n",
    "}\n",
    "\n",
    "def strip_accents(s: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "def normaliza_txt(x: object) -> str:\n",
    "    s = str(x).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)  # espaços múltiplos\n",
    "    return s\n",
    "\n",
    "def canoniza_pais(nome: str) -> str:\n",
    "    n = normaliza_txt(nome)\n",
    "    # aplica alias direto se bater\n",
    "    if n in ALIASES:\n",
    "        return ALIASES[n]\n",
    "    # fallback: tenta remover complemento entre parênteses\n",
    "    n_sem_par = re.sub(r\"\\s*\\(.*?\\)\\s*\", \"\", n).strip()\n",
    "    if n_sem_par in ALIASES:\n",
    "        return ALIASES[n_sem_par]\n",
    "    # fallback extra: compara sem acentos/maiusc.\n",
    "    n_key = strip_accents(n).lower()\n",
    "    for k, v in ALIASES.items():\n",
    "        if strip_accents(k).lower() == n_key:\n",
    "            return v\n",
    "    return n  # sem mapeamento: retorna como veio\n",
    "\n",
    "for xlsx in sorted(INPUT.glob(\"*.xlsx\")):\n",
    "    try:\n",
    "        df = pd.read_excel(xlsx, sheet_name=SHEET_NAME, engine=\"openpyxl\")\n",
    "    except ValueError as e:\n",
    "        print(f\"⚠️  {xlsx.name}: aba '{SHEET_NAME}' não encontrada. Pulando. ({e})\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  {xlsx.name}: erro ao abrir. Pulando. ({e})\")\n",
    "        continue\n",
    "\n",
    "    if \"name\" not in df.columns:\n",
    "        print(f\"⚠️  {xlsx.name}: coluna 'name' não existe na aba '{SHEET_NAME}'. Pulando.\")\n",
    "        continue\n",
    "\n",
    "    # normaliza e canoniza nomes de países\n",
    "    df[\"name\"] = df[\"name\"].map(canoniza_pais)\n",
    "\n",
    "    # filtra e ordena (mantém múltiplas linhas por país, ex.: por gridcode)\n",
    "    df_filtrado = df[df[\"name\"].isin(PAISES_ORDEM)].copy()\n",
    "    df_filtrado[\"__ordem_pais__\"] = pd.Categorical(\n",
    "        df_filtrado[\"name\"], categories=PAISES_ORDEM, ordered=True\n",
    "    )\n",
    "    sort_cols = [\"__ordem_pais__\"] + ([\"gridcode\"] if \"gridcode\" in df_filtrado.columns else [])\n",
    "    df_filtrado = df_filtrado.sort_values(sort_cols).drop(columns=\"__ordem_pais__\")\n",
    "\n",
    "    # relatório\n",
    "    encontrados = df_filtrado[\"name\"].drop_duplicates().tolist()\n",
    "    faltantes = [p for p in PAISES_ORDEM if p not in encontrados]\n",
    "\n",
    "    # salva com o mesmo nome\n",
    "    destino = OUTPUT / xlsx.name\n",
    "    try:\n",
    "        with pd.ExcelWriter(destino, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "            df_filtrado.to_excel(writer, sheet_name=SHEET_NAME, index=False)\n",
    "        print(\n",
    "            f\"✅  {xlsx.name}: {len(encontrados)}/15 países, \"\n",
    "            f\"{len(df_filtrado)} linhas salvas em '{destino.name}'.\"\n",
    "            + (f\" Faltantes: {', '.join(faltantes)}.\" if faltantes else \"\")\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌  {xlsx.name}: erro ao salvar. ({e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84b78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
